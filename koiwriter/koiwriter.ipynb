{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koiwriter\n",
    "Writes English word to Tsevhu (Koilang) and then Koiwrit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the excel sheet with the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pronunciation</th>\n",
       "      <th>POS</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Verb Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'eujkae</td>\n",
       "      <td>ʔœʒke</td>\n",
       "      <td>v</td>\n",
       "      <td>rot away</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'eujvha</td>\n",
       "      <td>ʔœʒβɑ</td>\n",
       "      <td>v</td>\n",
       "      <td>rot</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'iis'en</td>\n",
       "      <td>ʔɪsʔɛn</td>\n",
       "      <td>v</td>\n",
       "      <td>ripple; reflect light (often from water); spre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aekak</td>\n",
       "      <td>ekɑk</td>\n",
       "      <td>v</td>\n",
       "      <td>land on; slam/smack into; crash; hit hard enou...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aekkae</td>\n",
       "      <td>ekke</td>\n",
       "      <td>v</td>\n",
       "      <td>smack; hit hard enough to injure someone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>yrieun</td>\n",
       "      <td>əɾiœn</td>\n",
       "      <td>adj</td>\n",
       "      <td>loyal; faithful</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>yue</td>\n",
       "      <td>juɛ</td>\n",
       "      <td>adj</td>\n",
       "      <td>dry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>yul</td>\n",
       "      <td>jul</td>\n",
       "      <td>adj</td>\n",
       "      <td>early</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>yuvi</td>\n",
       "      <td>juvi</td>\n",
       "      <td>adj</td>\n",
       "      <td>dark grey (like rain clouds)</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>yvon</td>\n",
       "      <td>əvon</td>\n",
       "      <td>adj</td>\n",
       "      <td>safe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word Pronunciation  POS  \\\n",
       "0      'eujkae         ʔœʒke    v   \n",
       "1      'eujvha         ʔœʒβɑ    v   \n",
       "2      'iis'en        ʔɪsʔɛn    v   \n",
       "3        aekak          ekɑk    v   \n",
       "4       aekkae          ekke    v   \n",
       "...        ...           ...  ...   \n",
       "2521    yrieun         əɾiœn  adj   \n",
       "2522       yue           juɛ  adj   \n",
       "2523       yul           jul  adj   \n",
       "2524      yuvi          juvi  adj   \n",
       "2525      yvon          əvon  adj   \n",
       "\n",
       "                                                Meaning Verb Class  \n",
       "0                                              rot away          4  \n",
       "1                                                   rot          3  \n",
       "2     ripple; reflect light (often from water); spre...          1  \n",
       "3     land on; slam/smack into; crash; hit hard enou...          4  \n",
       "4              smack; hit hard enough to injure someone          4  \n",
       "...                                                 ...        ...  \n",
       "2521                                    loyal; faithful        NaN  \n",
       "2522                                                dry        NaN  \n",
       "2523                                              early        NaN  \n",
       "2524                       dark grey (like rain clouds)      color  \n",
       "2525                                               safe        NaN  \n",
       "\n",
       "[2526 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_pd = pd.read_excel(Path(\"koilang.xlsx\"), sheet_name=\"Dictionary\", usecols=\"A:E\")\n",
    "dictionary_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_to_koilang = True\n",
    "word_to_translate = \"sun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple options exist. Please choose one:\n",
      "         Word Pronunciation POS  \\\n",
      "1     aesiivh          esɪβ   v   \n",
      "2   kombaekae       kombeke   v   \n",
      "3         nak           nɑk   v   \n",
      "4     li'enak       liʔɛnɑk   n   \n",
      "5       Oitje           NaN   n   \n",
      "6        soem          soɛm   n   \n",
      "7     soemrha       soɛmr̥ɑ   n   \n",
      "8     soemsii        soɛmsɪ   n   \n",
      "9    soemsyun      soɛmsʲun   n   \n",
      "10       syun          sjun   n   \n",
      "\n",
      "                                              Meaning Verb Class  \n",
      "1   sink; drown; go below; slip under; under(groun...          3  \n",
      "2   divide apart; split apart; divide asunder (imp...          4  \n",
      "3                        sunbathe; sit out in the sun          1  \n",
      "4   lizard (lit. sunbathing shield (shield often r...     animal  \n",
      "5   earth deity (connected to a myth of the sun in...        NaN  \n",
      "6                                                 sun        NaN  \n",
      "7                      sunrise (can shorten to sorha)        NaN  \n",
      "8                       sunset (can shorten to sosii)        NaN  \n",
      "9                    sunlight (can shorten to sosyun)        NaN  \n",
      "10         light (usually natural light like the sun)        NaN  \n",
      "\n",
      "Chosen translation:\n",
      "      Word Pronunciation POS  \\\n",
      "1  aesiivh          esɪβ   v   \n",
      "\n",
      "                                             Meaning Verb Class  \n",
      "1  sink; drown; go below; slip under; under(groun...          3  \n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "if english_to_koilang:\n",
    "    results = dictionary_pd.loc[dictionary_pd['Meaning'].str.contains(word_to_translate)]\n",
    "else:\n",
    "    # Saved for future where reverse translation is done\n",
    "    results = dictionary_pd.loc[dictionary_pd['Word'].str.contains(word_to_translate)]\n",
    "\n",
    "results.set_index(\"Word\", inplace=True)\n",
    "results.reset_index(inplace=True)\n",
    "results.index += 1\n",
    "num_of_results = len(results.index)\n",
    "chosen_translation = None\n",
    "\n",
    "if num_of_results == 0:\n",
    "    print(\"No translations found.\")\n",
    "\n",
    "elif num_of_results == 1:\n",
    "    print(\"Translation:\")\n",
    "    chosen_translation = results.iloc[[0]]\n",
    "    \n",
    "elif num_of_results > 1:\n",
    "    print(\"Multiple options exist. Please choose one:\")\n",
    "    print(results, end=\"\\n\\n\")\n",
    "    \n",
    "    # Allow for a choice\n",
    "    valid_choice = False\n",
    "    \n",
    "    while not valid_choice:\n",
    "        choice = input(\"Choice (1, 2, 3, ...): \")\n",
    "        try:\n",
    "            if choice.isdigit() and int(choice) in range(1, int(len(results.index)) + 1):\n",
    "                choice = int(choice)\n",
    "                chosen_translation = results.iloc[[choice - 1]]\n",
    "                valid_choice = True\n",
    "        except:\n",
    "            print(f\"Input is not a number or it is not in range {choice}\")\n",
    "    \n",
    "    print(f\"Chosen translation:\")\n",
    "\n",
    "print(chosen_translation)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate word into writeable parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules_for_tokens(word: str) -> List[str]:\n",
    "    \"\"\"All the words in Koilang only have at most two characters to represent a ripple, \n",
    "    and it's either a vowel or \"h\", so separating a word into tokens that can map to\n",
    "    the ripples is very straightforward. If the language evolves with more complex rules,\n",
    "    I recommend switching to using a parser like PEST or something similar.\n",
    "\n",
    "    Args:\n",
    "        word (str): Word to tokenize\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of tokens as strings\n",
    "    \"\"\"\n",
    "    def both_chars_go_together(char_before: str, char_now: str) -> bool:\n",
    "        # CONSONANTS\n",
    "        # Ending in 'h'\n",
    "        if char_now == 'h' and char_before in ['c', 'k', 'p', 's', 't', 'v', ]:\n",
    "            return True\n",
    "        \n",
    "        # VOWELS\n",
    "        # Ending in 'e'\n",
    "        if char_now == 'e' and char_before in ['a']:\n",
    "            return True\n",
    "        \n",
    "        # Ending in 'i'\n",
    "        if char_now == 'i' and char_before in ['a', 'i', 'o']:\n",
    "            return True\n",
    "        \n",
    "        # Ending in 'e'\n",
    "        if char_now == 'u' and char_before in ['a', 'e']:\n",
    "            return True\n",
    "\n",
    "        # None of the previous conditions where met\n",
    "        return False\n",
    "    word = word.strip().lower()\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    # Start at second char\n",
    "    i = 1\n",
    "    word_length = len(word)\n",
    "    last_char_index = word_length - 1\n",
    "    while i < word_length:\n",
    "        \n",
    "        char_before = word[i-1]\n",
    "        char_now = word[i]\n",
    "        \n",
    "        # Add both chars as one token or just add char_before\n",
    "        if both_chars_go_together(char_before, char_now):\n",
    "            tokens.append(f'{char_before}{char_now}')\n",
    "            \n",
    "            if i + 1 == last_char_index:  # If only one char left after char_now\n",
    "                tokens.append(word[i+1])  # Just add that last char\n",
    "                break  # End tokenizing\n",
    "            else:\n",
    "                i += 1  # Skip char_now becoming char_before in the next iteration\n",
    "            \n",
    "        else:\n",
    "            tokens.append(char_before)  # Add char normally\n",
    "            if i == last_char_index:  # If char_now is the last char in the word\n",
    "                tokens.append(char_now)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ae', 's', 'ii', 'vh']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = rules_for_tokens(chosen_translation[\"Word\"].values[0])\n",
    "# tokens = rules_for_tokens(\"Tsevhu\")\n",
    "for i, t in enumerate(tokens):\n",
    "    if t == \"'\":\n",
    "        tokens[i] = \"`\"\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the best orientation for each ripple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get density data\n",
    "with open(Path(\"ripples/density_data.json\")) as f:\n",
    "    density_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_orientation = {\n",
    "    \"0\": {\n",
    "        \"N\": \"N\",\n",
    "        \"NE\": \"NE\",\n",
    "        \"E\": \"E\",\n",
    "        \"SE\": \"SE\",\n",
    "        \"S\": \"S\",\n",
    "        \"SW\": \"SW\",\n",
    "        \"W\": \"W\",\n",
    "        \"NW\": \"NW\"\n",
    "    },\n",
    "    \"1\": {\n",
    "        \"N\": \"E\",\n",
    "        \"NE\": \"SE\",\n",
    "        \"E\": \"S\",\n",
    "        \"SE\": \"SW\",\n",
    "        \"S\": \"W\",\n",
    "        \"SW\": \"NW\",\n",
    "        \"W\": \"N\",\n",
    "        \"NW\": \"NE\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"N\": \"S\",\n",
    "        \"NE\": \"SW\",\n",
    "        \"E\": \"W\",\n",
    "        \"SE\": \"NW\",\n",
    "        \"S\": \"N\",\n",
    "        \"SW\": \"NE\",\n",
    "        \"W\": \"E\",\n",
    "        \"NW\": \"SE\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"N\": \"W\",\n",
    "        \"NE\": \"NW\",\n",
    "        \"E\": \"N\",\n",
    "        \"SE\": \"NE\",\n",
    "        \"S\": \"E\",\n",
    "        \"SW\": \"SE\",\n",
    "        \"W\": \"S\",\n",
    "        \"NW\": \"SW\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# Choose orientations based on densities\n",
    "orientations = []  \n",
    "previous_dense_above_dir = None\n",
    "previous_quarters = None\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    if i == 0:\n",
    "        # Only need to record dense above direction as is. The first token is never rotated.\n",
    "        previous_dense_above_dir: List[str] = density_data[token]['dense_above_dir']\n",
    "        previous_quarters: int = density_data[token]['quarters']\n",
    "        orientations.append(0)\n",
    "        continue\n",
    "    \n",
    "    # Have a temporary orientation which starts where the previous ripple ended\n",
    "    temp_orientation = (orientations[i-1] + previous_quarters) % 4\n",
    "    \n",
    "    # CHOOSE ORIENTATION BASE ON DENSITY\n",
    "    # Where it is dense below, it must not coincide with where the previous one is dense above\n",
    "    dense_below_dir: List[str] = density_data[token]['dense_below_dir']\n",
    "    chosen_orientation = 0\n",
    "    for orientation in range(4):\n",
    "        temp_dense_below_dir = [translate_orientation[str((orientation + temp_orientation) % 4)][d] for d in dense_below_dir]\n",
    "        \n",
    "        # Check intersection. Assumes orientation choices have been taken into consideration\n",
    "        common_dirs = set(temp_dense_below_dir).intersection(set(previous_dense_above_dir))\n",
    "        if not common_dirs:\n",
    "            # No clash, valid orientation found\n",
    "            chosen_orientation = (orientation + temp_orientation) % 4\n",
    "            break\n",
    "    \n",
    "    orientations.append(chosen_orientation)\n",
    "    \n",
    "    # Keep information to help next token orientation\n",
    "    previous_dense_above_dir = [translate_orientation[str(chosen_orientation)][d] for d in density_data[token]['dense_above_dir']]\n",
    "    previous_quarters: int = density_data[token]['quarters']\n",
    "\n",
    "orientations\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n",
    "\n",
    "# Create the output file\n",
    "with open(Path(\"output.svg\"), 'w') as output_f:\n",
    "    view_box_val = 500\n",
    "    view_box_val2 = 500\n",
    "    output_f.write(f'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"{view_box_val}\" height=\"{view_box_val}\" viewBox=\"0 0 {view_box_val2} {view_box_val2}\">\\n')\n",
    "    \n",
    "    # Obtain the SVG files for the tokens and add it to the image\n",
    "    num_tokens = len(tokens)\n",
    "    for i, token in enumerate(tokens):\n",
    "        doc = parse(str(Path(f\"ripples/images/{token}.svg\")))\n",
    "        scale_value = 0.65 ** (num_tokens - (i + 1))\n",
    "        \n",
    "        output_f.write(f'\\t<g id=\"{token}_{i}\" transform-origin=\"250 250\" transform=\"scale({scale_value}) rotate({90 * orientations[i]})\">\\n')\n",
    "        for child_elem in doc.getElementsByTagName(\"path\"):\n",
    "            output_f.write(f'\\t\\t{child_elem.toprettyxml()}\\n')\n",
    "        output_f.write(f'\\t</g>\\n')\n",
    "    \n",
    "    output_f.write('</svg>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
